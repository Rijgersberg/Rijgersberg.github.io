[{"content":"Drie vrijwilligers. Een paar weken aan werk. Dat is wat er nodig was om een taal op te nemen in BigScience BLOOM, het open meertalige taalmodel met maar liefst 176 miljard parameters dat halverwege 2022 uitkwam. Het moest een open, meertalig alternatief voor GPT-3 worden. Uiteindelijk zijn er 46 talen van over de hele wereld beland in de dataset waarmee BLOOM getrained is. Ook relatief kleine talen als het Baskisch en het Catalaans kregen het voor elkaar om opgenomen te worden. Het Nederlands niet. Hoe kan dat?\nBigScience, big dreams Het begon allemaal in 2021. Een groep van meer dan 1.000 onderzoekers had zich verenigd in het virtuele onderzoekscollectief BigScience. Vermoedelijk getriggerd door de capaciteiten van GPT-3 en bezorgd om de opkomst van de grote taalmodellen die door de grote techbedrijven voor angstvallig voor zichzelf gehouden worden, deden ze vanaf mei 2021 mee aan een √©√©njarige open onderzoeks-workshop op het gebied van meertalige grote taalmodellen.\nGefinancierd door de Franse overheid en de Frans-Amerikaanse start-up Hugging Face \u0026mdash; √©√©n van de hotste bedrijven op het gebied van AI \u0026mdash; wilden ze twee dingen bereiken:\neen zeer grote meertalige tekst-dataset samenstellen van hoge kwaliteit, later ROOTS genoemd; en daarmee een zeer groot meertalig taalmodel trainen dat GPT-3 naar de kroon kon steken: BLOOM. Zij wilden dit zo open mogelijk doen. Het model moest door iedereen te downloaden zijn, zodat je het kunt gebruiken voor toepassingen waar je gesloten modellen als GPT-3 niet voor kunt gebruiken. Als je bijvoorbeeld vertrouwelijke data hebt die je niet naar een Amerikaans techbedrijf wil sturen. Of als je het model wilt onderzoeken op mogelijke biases voordat je het inzet. Of als je gewoon uit principe wilt weten op welke data het model wel en niet gezien heeft in de trainingsfase.\nOm dit voor elkaar te krijgen zijn onderzoekers betrokken vanuit allerlei verschillende vakgebieden en zijn dataset en model vanuit meerdere gezichtspunten onderzocht:\n‚ÄçDuring the workshop, the participants plan to investigate the dataset and the model from all angles: bias, social impact, capabilities, limitations, ethics, potential improvements, specific domain performances, carbon impact, general AI/cognitive research landscape.\nHet hele initiatief is ook uitvoerig beschreven in drie losse wetenschappelijk papers: over het proces, over de dataset en over het model.\nDe BigScience werkgroepen. Akiki, Christopher, et al. \u0026ldquo;BigScience: A case study in the social construction of a multilingual large language model.\u0026rdquo; arXiv preprint arXiv:2212.04960 (2022).\nBLOOM: open, ethisch en klimaatvriendelijk Het resultaat: BLOOM, het BigScience Large Open-science Open-access Multilingual Language Model, gelanceerd in juli 2022. Een groot open taalmodel van 176 miljard parameters dat getraind is op 46 verschillende talen (en 13 verschillende programmeertalen). Het is voor iedereen vrij te downloaden, te bestuderen en te gebruiken1. En niet alleen het uiteindelijke model is beschikbaar, maar ook tussentijdse checkpoints van het model van tijdens het trainen zijn met iedereen gedeeld.\nHet model is in 117 dagen getraind op ruim 3.000 GPUs van de Franse Jean Zay supercomputer. Kosten? Ongeveer 3 miljoen euro. De Franse supercomputer is ook de bron van de claim van de klimaatvriendelijkheid van het model. BigScience gaat er namelijk prat op dat de benodigde elektriciteit grotendeels opgewekt is met kernenergie. Het trainen van het model heeft daardoor een lage CO2-uitstoot met zich meegebracht.\nDe Jean Zay Supercomputer. ¬© Phototh√®que CNRS/Cyril Fr√©sillon\nDe focus op openheid en ethiek leverde lof op vanuit de academische wereld. Onderzoekers van de Stanford University publiceerden recent een onderzoek naar grote taalmodellen. Ze brachten in kaart welke van de grote taalmodellen nu al het best voldoen aan de eisen uit de voorlopige tekst van de EU AI Act: de Verordening Kunstmatige Intelligentie van de Europese Unie. BLOOM scoorde verreweg het best. Ook de Radboud Universiteit deed een vergelijkend onderzoek naar de openheid van taalmodellen (leaderboard, paper). Het meest open model? Wederom BLOOM.\nIn 2022 werd het mode om elk groot taalmodel als een foundation model te beschouwen, en zo\u0026rsquo;n model te finetunen op chatconversaties om een interactief model te maken √° la OpenAI\u0026rsquo;s InstructGPT. Begin november 2022 is er daarom ook nog een chat-variant van BLOOM uitgebracht: BLOOMZ (website, paper, GitHub). De buzz daaromheen is helaas een beetje verloren gegaan in het geweld van ChatGPT, dat nog geen vier weken later werd gelanceerd.\nScores van grote taalmodellen op de eisen uit de AI-Act. Bommasani, Rishi et al. \u0026ldquo;Do Foundation Model Providers Comply with the EU AI Act?\u0026rdquo; https://crfm.stanford.edu/2023/06/15/eu-ai-act.html (2023).\nROOTS-corpus Om BLOOM te kunnen trainen moest er eerst een dataset samengesteld worden: het ROOTS-corpus. Ook hier weer lag de focus op openheid en ethiek. Van alle datasets die in ROOTS zijn opgenomen werden dataset cards gepubliceerd. De data zelf is opgeschoond en gededupliceerd. Persoonsgegevens als telefoonnummers, e-mailadressen en usernames op social media zijn zo veel mogelijk automatisch verwijderd. Zo is ROOTS uitgegroeid tot een dataset van 1,6 terabyte aan tekstdata in 46 natuurlijke talen, aangevuld met 13 verschillende programmeertalen.\nDie 46 verschillende talen vormen een nogal interessante mengelmoes. Uiteraard ontbreken high-resource Europese talen als Engels, Frans, Spaans en Portugees niet in dit toch grotendeels Europese project. Daarnaast maken ook Arabisch en Chinees2 acte de pr√©sence. Tenslotte zijn er bewust een aantal low-resource-talen aan de dataset toegevoegd, zoals meerdere talen uit de Niger-Congo-taalfamilie waarvoor maar weinig geschreven tekst beschikbaar is.\nTalen in het ROOTS-corpus. Grafiek uit de BLOOM model card.\nOpvallende ontbrekende talen? Allereerst: het Duits. Daarnaast het Russisch, en eigenlijk alle Slavische talen, net als de Scandinavische talen. En het Nederlands dus. Wel aanwezig: relatief kleine talen als het Catalaans en het Baskisch. Hoe kan dat?\nTaalselectie Hoe werd bepaald welke talen wel en welke talen niet meegenomen werden? Het antwoord is eigenlijk vrij simpel, maar vreemd genoeg niet te vinden in het paper dat het ROOTS-corpus beschrijft. In plaats daarvan komt het aan bod in het paper van BLOOM zelf, op pagina 10 en 11.\nLanguage Choices These considerations led us to an incremental process for choosing which languages were to be included in the corpus. We started with a list of eight of the world‚Äôs largest languages by number of speakers for which we did active outreach in the early stages of the project to invite fluent speakers to join the data efforts. Then, on the recommendation of language communities (Nekoto et al., 2020) we expanded Swahili in the original selection to the category of Niger-Congo languages, and Hindi and Urdu to Indic languages (Kunchukuttan et al., 2020). Finally, we proposed that any group of 3 or more participants fluent in an additional language could add it to the supported list if they would commit to selecting sources and guiding processing choices in the language in order to avoid common issues with corpora selected through automatic language identification without specific language expertise (Caswell et al., 2022).\nScao, Teven Le, et al. \u0026ldquo;Bloom: A 176b-parameter open-access multilingual language model.\u0026rdquo; arXiv preprint arXiv:2211.05100 (2022)\nVrijwilligers dus. Om precies te zijn: minimaal drie vrijwilligers die de taal vloeiend spreken en bereid waren om bronnen te selecteren, √©n bereid waren om te bewaken dat het verwerken van die bronnen op een goede manier gebeurde. Ik weet de details niet precies, maar ik schat het op hooguit enkele weken aan werk. Dat waren de kosten om als Nederlands mee te profiteren van een miljoeneninvestering. Blijkbaar waren er niet minimaal drie vrijwilligers beschikbaar die dat voor het Nederlands wilden of konden doen.\nGemiste kans? Had het ook anders kunnen lopen? Misschien wel. Ik hoorde zelf pas van het bestaan van BigScience toen het al te laat was. Vermoedelijk geldt dit ook voor anderen in Nederland of Belgi√´ die er graag aan hadden bijgedragen. Ja, als ik mee had willen doen had ik ergens die tijd vandaan moeten halen. Maar met een helder doel voor ogen en met het duidelijke belang dat we er als Nederland mee hebben was het vast wel gelukt. Het is niet vaak dat je met een kleine tijdsbesteding mee kunt liften op andermans miljoeneninvestering. Ik heb waarschijnlijk al langer in vergaderingen gezeten over consortia voor hypothetische toekomstige Nederlandstalige grote taalmodellen dan ik nodig gehad zou hebben om het Nederlands aan BLOOM toe te voegen.\nAan de andere kant: alle openheid ten spijt is BLOOM nou ook weer niet h√©t taalmodel geworden dat alle andere taalmodellen heeft doen vergeten. Met 176 miljard parameters is het inderdaad heel groot, maar BLOOM is van een eerdere generatie dan bijvoorbeeld LLaMA van Meta (70 miljard parameters), dat een stuk effici√´nter met de parameters omgaat. In de ü§ó Open LLM Leaderboard, een ranglijst van best presterende grote taalmodellen, is BLOOM-178B niet eens opgenomen. Tekenend voor het gebrek aan interesse van de open source community, schat ik zo in. Een kleinere variant van BLOOM, BLOOM-7b1 met \u0026ldquo;maar\u0026rdquo; 7 miljard parameters, staat wel op de lijst, maar bevindt zich ergens in de onderste helft. BLOOMZ \u0026mdash; de chatversie van BLOOM \u0026mdash; komt ook niet op het leaderboard voor.\nBLOOM-7b1 op het ü§ó Open LLM Leaderboard.\nMaar wat meet dat leaderboard eigenlijk? Prestaties in het Engels. De grote open taalmodellen voor het Nederlands staan nog heel erg in de kinderschoenen. Er bestaat naar mijn weten niet eens zo\u0026rsquo;n leaderbord voor het Nederlands.3 En als er al een leaderboard zou bestaan voor open Nederlandstalige modellen: een hypothetische BLOOM dat ook op het Nederlands getraind zou zijn zou bovenaan de lijst prijken. In de lage landen der blinden zou √©√©noog koning zijn.\nLessen Welke lessen kan de Nederlandstalige AI-community wat mij betreft hieruit trekken?\nOm te beginnen: we moeten m√©√©doen. De grote Amerikaanse techbedrijven zien Nederland en het Nederlands slechts als bijzaak, en geef ze eens ongelijk. Als sprekers van een kleine taal in een grote wereld moeten we opportunistisch zijn. Als we kunnen meeliften op een bestaand initiatief: capaciteit vrijmaken en doen! Vrijwilligers gezocht? Wij hebben ze klaarstaan! Niet alleen grootse projectplannen, maar vooral ook ijverige handjes.\nWe moeten voorkomen dat we een volgende keer weer de boot missen. Maar dat alleen is niet genoeg. We moeten als land \u0026mdash; en dus als overheid \u0026mdash; ook investeren in het samenstellen, opschonen en publiceren van Nederlandstalige datasets. Datasets voor het trainen, datasets voor het maken van chatbots en agents, datasets om prestaties te evalueren en om bias te meten. We moeten die datasets overal onder de aandacht brengen. Publiceren op alle plekken waar bedrijven en academici die een taalmodel willen trainen op zoek zijn naar data. Dus niet alleen op data.overheid.nl en de SURF Repository, maar ook op Github, op Hugging Face datasets en op r/MachineLearning. Pushen tot je er niet meer omheen kunt.\nNederlands als bijvangst. Niet per ongeluk, maar als nationale strategie.\nEn daar houdt het niet op. Als maatschappij moeten we ons afvragen waarom technologiebedrijven van eigen bodem momenteel niet dezelfde rol kunnen spelen voor het Nederlands die big tech wel speelt voor het Engels. Waar zijn de open modellen van Albert Heijn, Bol.com, Booking.com en Thuisbezorgd? En waarom kan het Nationaal Groeifonds wel meer dan 200 miljoen euro steken in het AINed-programma, maar kan ik vervolgens op hun website nul ontwikkelde open source datasets of modellen vinden?\nEn als ik dan toch bezig ben: denkt er √ºberhaupt nog iemand aan taalmodellen voor het Fries?\nStrict gezien is het model niet open source. Het is door BigScience vrijgegeven onder de Responsible AI License (RAIL). Die stelt g√©√©n restricties aan hergebruik, distributie, commercialisering en aanpassingen, zolang je het maar niet inzet voor √©√©n van de restricted use cases in Appendix A. Van tevoren toestemming vragen is niet nodig.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSpecifiek: geschreven Vereenvoudigd Chinees\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nElke serieuze poging om een groot Nederlandstalig taalmodel te trainen zou eigenlijk moeten beginnen met het samenstellen van datasets waarmee je zo\u0026rsquo;n model fatsoenlijk zou kunnen evalueren.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://goingdutch.ai/nl/posts/bigscience-bloom/","summary":"Drie vrijwilligers. Een paar weken aan werk. Dat is wat er nodig was om een taal op te nemen in BigScience BLOOM, het open meertalige taalmodel met maar liefst 176 miljard parameters dat halverwege 2022 uitkwam. Het moest een open, meertalig alternatief voor GPT-3 worden. Uiteindelijk zijn er 46 talen van over de hele wereld beland in de dataset waarmee BLOOM getrained is. Ook relatief kleine talen als het Baskisch en het Catalaans kregen het voor elkaar om opgenomen te worden.","title":"De boot gemist: waarom het Nederlands ontbreekt in het belangrijkste open Europese taalmodel"},{"content":"Ik kan niet vaak publiekelijk iets uit de doeken doen over het soort zaken dat we bij het Nederlands Forensisch Instituut doen met behulp van AI, maar op de afgelopen EuroPython 2023 in Praag heb ik namens het NFI iets kunnen vertellen over een zaak die een paar jaar terug speelde en waar het NFI al eerder een persbericht over uitstuurde: het Threat-to-Life-project.\nPolitie kon live meelezen met criminelen Het was de politie in 2020 gelukt om live mee te kunnen lezen bij een aanbieder van zogenaamde cryptotelefoons: gemodificeerde telefoons die \u0026mdash; tegen een flinke betaling \u0026mdash; gebruikt werden om versleuteld te communiceren in het criminele circuit. Het was niet de eerste keer en ook niet de laatste dat de politie dat lukte. Het gebeurt dusdanig vaak dat er intussen zelfs een een overzichtslijstje bestaat van dergelijke operaties tegen aanbieders van cryptotelefoons.\nIn de praktijk blijkt dat sommige criminelen zich bijzonder veilig wanen bij het gebruik van dergelijke cryptotelefoons. Ze sturen dan ook zonder blikken of blozen de meest gevoelige en belastende berichten onverbloemd over de lijn. Communicatie is key in de zakenwereld blijkbaar, wat voor soort zaken je ook doet.\nDetecteren van threat-to-life-berichten Kunnen meelezen is √©√©n ding, maar als het gaat om een grote stroom berichten dan wil je dat sommige typen berichten wel echt op tijd door de politie beoordeeld worden. Als er bijvoorbeeld gesproken wordt over het voorbereiden van mishandelingen, ontvoeringen en liquidaties, dan moet er op tijd actie ondernomen kunnen worden om die te kunnen voorkomen. Daar was dus iets voor nodig: een threat-to-life-detector.\nZiedaar de uitdaging: train een classificatie-model dat threat-to-life berichten kan vinden in grote verzamelingen niet-threat-to-life-berichten afkomstig van cryptotelefoons. En hoewel de taak \u0026mdash; classificatie \u0026mdash; op zich niet zo vernieuwend is, is het nog niet triviaal om zo\u0026rsquo;n model van de grond te krijgen. Je moet immers een model maken dat kan omgaan met het soort taal dat in dit soort berichten voorkomt: informeel en doorspekt met straattaal en jargon. Heel wat anders dat de taal die tegenkomt als je Wikipedia scrapet dus.\nDaarnaast moet je voldoende trainingsdata weten te verzamelen \u0026mdash; voorbeelden van het soort berichten waar je naar op zoek bent. En die waren dus relatief zeldzaam in de grote stroom met andere berichten. Een beetje een kip-ei-probleem eigenlijk.\nEuroPython 2023 Hoe we die problemen opgelost hebben kan je zien in de live-opname van mijn praatje hieronder. Het was een relatief kort praatje voor een publiek van programmeurs, niet per s√© van data scientists. Ik heb er daarom voor gekozen om niet heel diep op de details van de deep learning in te gaan, en in plaats daarvan wat meer tijd te besteden aan de context van het hele verhaal.\nMaar juist daarom is het denk ik een aardig kijkje in de keuken: het laat zien waar je tegenaan loopt bij de inzet van AI voor een zaak als deze.\nTientallen zware geweldsmisdrijven voorkomen En het resultaat? In het persbericht van de politie uit juli 2020 werd de voorlopige balans opgemaakt van de politieoperatie. Daaruit blijkt ook wat de politie heeft kunnen doen met de threat-to-life-signalen die uit het onderzoek voortkwamen.\nHieronder de voorlopige balans:\nMeer dan 100 verdachten aangehouden voor zeer zware delicten Bijna 20 miljoen euro cash in beslag genomen De inbeslagname van 8000 kilo coca√Øne en ruim 1200 kilo crystal meth Er zijn 19 synthetische drugslabs ontmanteld Ook werden tientallen vuurwapens van straat gehaald Alleen al in Nederland werden de afgelopen maanden ruim 3000 signalen verwerkt die levensbedreigend leken. Door steeds tijdig in te grijpen heeft de politie tientallen zware geweldsmisdrijven kunnen voorkomen, waaronder op handen zijnde ontvoeringen, afpersingen, liquidaties en martelingen. Intussen, drie jaar later, is Europol nog steeds de score aan het bijhouden van de hele operatie. Volgens hun staat de teller intussen op meer dan 6.500 arrestaties en is er voor bijna 900 miljoen euro aan cash en tegoeden in beslag genomen.\nEn nu? Cryptotelefoons en ontcijferde berichten waren en zijn nog steeds zeer actueel in strafzaken. Dat wordt nogmaals ge√Øllustreerd door een recent nieuwsartikel van NOS over hoe de digitale afdeling van het NFI honderden individuele crypotelefoons wist te kraken.\n","permalink":"https://goingdutch.ai/nl/posts/europython-2023-ttl/","summary":"Ik kan niet vaak publiekelijk iets uit de doeken doen over het soort zaken dat we bij het Nederlands Forensisch Instituut doen met behulp van AI, maar op de afgelopen EuroPython 2023 in Praag heb ik namens het NFI iets kunnen vertellen over een zaak die een paar jaar terug speelde en waar het NFI al eerder een persbericht over uitstuurde: het Threat-to-Life-project.\nPolitie kon live meelezen met criminelen Het was de politie in 2020 gelukt om live mee te kunnen lezen bij een aanbieder van zogenaamde cryptotelefoons: gemodificeerde telefoons die \u0026mdash; tegen een flinke betaling \u0026mdash; gebruikt werden om versleuteld te communiceren in het criminele circuit.","title":"Mijn praatje op EuroPython 2023: \"Threat to Life ‚Äî Preventing Planned Murders with Python\""}]